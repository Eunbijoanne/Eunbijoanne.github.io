{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eunbijoanne/Eunbijoanne.github.io/blob/master/%EB%94%A5%EB%9F%AC%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "I0eOYcBDsxJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Dense, Dropout, Embedding, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Qe5c5e62pDx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNgDyRzDjfch"
      },
      "outputs": [],
      "source": [
        "# 데이터 로드\n",
        "(tr_x, tr_y), (tt_x, tt_y) = imdb.load_data(num_words=100)\n",
        "X = np.concatenate([tr_x, tt_x])\n",
        "y = np.concatenate([tr_y, tt_y])\n",
        "\n",
        "# 데이터 전처리\n",
        "for i in range(len(X)):\n",
        "    X[i] = [w for w in X[i] if w > 2]\n",
        "\n",
        "# 데이터 분할\n",
        "x_data, tt_x, y_data, tt_y = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "tr_x, val_x, tr_y, val_y = train_test_split(x_data, y_data, test_size=0.2, random_state=42, stratify=y_data)\n",
        "\n",
        "# 패딩\n",
        "p_tr_x = pad_sequences(tr_x, maxlen=100)\n",
        "p_tt_x = pad_sequences(tt_x, maxlen=100)\n",
        "p_val_x = pad_sequences(val_x, maxlen=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성\n",
        "model = Sequential([\n",
        "    Input(shape=(100,)),  # 명시적으로 입력 형태 지정\n",
        "    Embedding(100, 32),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss=binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "fF_w97Nij2yf",
        "outputId": "b83d64ad-ed55-42ca-8f60-9e1cfb0e0171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m3,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m24,832\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,993\u001b[0m (160.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,993</span> (160.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,993\u001b[0m (160.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,993</span> (160.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기 종료 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(p_tr_x, tr_y,\n",
        "                    epochs=30,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(p_val_x, val_y),\n",
        "                    callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "j2W-RCYLj2pE",
        "outputId": "ebfb9435-c74c-4a88-845c-0176c4b59046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.6229 - loss: 0.6389 - val_accuracy: 0.7061 - val_loss: 0.5679\n",
            "Epoch 2/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 146ms/step - accuracy: 0.7102 - loss: 0.5662 - val_accuracy: 0.7199 - val_loss: 0.5400\n",
            "Epoch 3/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 125ms/step - accuracy: 0.7212 - loss: 0.5480 - val_accuracy: 0.7181 - val_loss: 0.5388\n",
            "Epoch 4/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 127ms/step - accuracy: 0.7267 - loss: 0.5497 - val_accuracy: 0.7291 - val_loss: 0.5330\n",
            "Epoch 5/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 124ms/step - accuracy: 0.7296 - loss: 0.5414 - val_accuracy: 0.7326 - val_loss: 0.5339\n",
            "Epoch 6/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 134ms/step - accuracy: 0.7300 - loss: 0.5413 - val_accuracy: 0.7361 - val_loss: 0.5186\n",
            "Epoch 7/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 129ms/step - accuracy: 0.7354 - loss: 0.5328 - val_accuracy: 0.7397 - val_loss: 0.5139\n",
            "Epoch 8/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 125ms/step - accuracy: 0.7476 - loss: 0.5209 - val_accuracy: 0.7427 - val_loss: 0.5078\n",
            "Epoch 9/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 126ms/step - accuracy: 0.7483 - loss: 0.5151 - val_accuracy: 0.7413 - val_loss: 0.5197\n",
            "Epoch 10/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 124ms/step - accuracy: 0.7493 - loss: 0.5161 - val_accuracy: 0.7486 - val_loss: 0.5065\n",
            "Epoch 11/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 124ms/step - accuracy: 0.7578 - loss: 0.5058 - val_accuracy: 0.7453 - val_loss: 0.5047\n",
            "Epoch 12/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 139ms/step - accuracy: 0.7619 - loss: 0.5002 - val_accuracy: 0.7504 - val_loss: 0.5016\n",
            "Epoch 13/30\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 134ms/step - accuracy: 0.7595 - loss: 0.5010 - val_accuracy: 0.7506 - val_loss: 0.5041\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1774b0be2580>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m history = model.fit(p_tr_x, tr_y, \n\u001b[0m\u001b[1;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 결과 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# 훈련 정확도와 검증 정확도 그래프\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# 훈련 손실과 검증 손실 그래프\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 테스트 세트에 대한 평가\n",
        "test_loss, test_acc = model.evaluate(p_tt_x, tt_y)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "iq6ZfghtkG0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras 데이터셋 전처리 가이드"
      ],
      "metadata": {
        "id": "4hrT_pfxs2O3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 가이드에서는 Keras에서 제공하는 데이터셋을 사용할 때의 전처리 방법을 설명합니다. Boston Housing 데이터셋(회귀)과 CIFAR-10 데이터셋(이미지 분류)을 예로 들어 설명하겠습니다.\n",
        "\n",
        "## 1. Boston Housing 데이터셋 (회귀 문제)\n",
        "\n",
        "### 데이터 로드\n",
        "```python\n",
        "from keras.datasets import boston_housing\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "```\n",
        "\n",
        "### 전처리 단계\n",
        "\n",
        "1. 특성 정규화 (Feature Normalization)\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "```\n",
        "\n",
        "2. 데이터 형태 확인 및 조정 (필요한 경우)\n",
        "```python\n",
        "print(\"훈련 데이터 형태:\", x_train_scaled.shape)\n",
        "print(\"테스트 데이터 형태:\", x_test_scaled.shape)\n",
        "print(\"훈련 레이블 형태:\", y_train.shape)\n",
        "print(\"테스트 레이블 형태:\", y_test.shape)\n",
        "```\n",
        "\n",
        "3. 모델 구성 예시\n",
        "```python\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(13,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "```\n",
        "\n",
        "4. 모델 훈련\n",
        "```python\n",
        "history = model.fit(x_train_scaled, y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    verbose=1)\n",
        "```\n",
        "\n",
        "## 2. CIFAR-10 데이터셋 (이미지 분류 문제)\n",
        "\n",
        "### 데이터 로드\n",
        "```python\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "```\n",
        "\n",
        "### 전처리 단계\n",
        "\n",
        "1. 픽셀 값 정규화\n",
        "```python\n",
        "x_train_normalized = x_train.astype('float32') / 255\n",
        "x_test_normalized = x_test.astype('float32') / 255\n",
        "```\n",
        "\n",
        "2. 레이블 원-핫 인코딩\n",
        "```python\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, 10)\n",
        "y_test_encoded = to_categorical(y_test, 10)\n",
        "```\n",
        "\n",
        "3. 데이터 형태 확인\n",
        "```python\n",
        "print(\"훈련 이미지 형태:\", x_train_normalized.shape)\n",
        "print(\"테스트 이미지 형태:\", x_test_normalized.shape)\n",
        "print(\"훈련 레이블 형태:\", y_train_encoded.shape)\n",
        "print(\"테스트 레이블 형태:\", y_test_encoded.shape)\n",
        "```\n",
        "\n",
        "4. 데이터 증강 (선택사항)\n",
        "```python\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(x_train_normalized)\n",
        "```\n",
        "\n",
        "5. 모델 구성 예시\n",
        "```python\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "6. 모델 훈련\n",
        "```python\n",
        "# 데이터 증강을 사용하지 않는 경우\n",
        "history = model.fit(x_train_normalized, y_train_encoded,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=50,\n",
        "                    batch_size=64,\n",
        "                    verbose=1)\n",
        "\n",
        "# 데이터 증강을 사용하는 경우\n",
        "history = model.fit(datagen.flow(x_train_normalized, y_train_encoded, batch_size=64),\n",
        "                    steps_per_epoch=len(x_train_normalized) // 64,\n",
        "                    epochs=50,\n",
        "                    validation_data=(x_test_normalized, y_test_encoded),\n",
        "                    verbose=1)\n",
        "```\n",
        "\n",
        "## 주의사항\n",
        "- 데이터셋마다 특성이 다르므로, 적절한 전처리 방법을 선택해야 합니다.\n",
        "- 테스트 데이터에는 훈련 데이터의 통계를 사용하여 전처리해야 합니다 (예: StandardScaler의 경우).\n",
        "- 이미지 데이터의 경우, 채널 순서가 'channels_last' (높이, 너비, 채널)인지 확인하세요. 필요하다면 `keras.backend.image_data_format()`으로 확인할 수 있습니다.\n",
        "- 대용량 데이터셋의 경우, `fit_generator`를 사용하여 메모리 효율적으로 훈련할 수 있습니다."
      ],
      "metadata": {
        "id": "1w-1U0O8s0Bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 딥러닝 모델 구성 및 컴파일 가이드"
      ],
      "metadata": {
        "id": "C2icVf3EmBwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 모델 구성 (Model Architecture)\n",
        "\n",
        "### Sequential API 사용\n",
        "간단한 모델의 경우:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(100,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "```\n",
        "\n",
        "### Functional API 사용\n",
        "복잡한 모델이나 다중 입력/출력 모델의 경우:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "inputs = Input(shape=(100,))\n",
        "x = Dense(64, activation='relu')(inputs)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "```\n",
        "\n",
        "### 주요 요령:\n",
        "1. 문제에 적합한 층(Layer) 선택 (예: CNN for 이미지, RNN/LSTM for 시퀀스 데이터)\n",
        "2. 적절한 활성화 함수 선택 (예: ReLU for 은닉층, Sigmoid for 이진 분류)\n",
        "3. 과적합 방지를 위한 정규화 기법 사용 (예: Dropout, BatchNormalization)\n",
        "4. 모델 복잡도 조절 (너무 깊거나 넓지 않게)\n",
        "\n",
        "## 2. 모델 컴파일 (Model Compilation)\n",
        "\n",
        "기본 구조:\n",
        "```python\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "### 주요 요령:\n",
        "1. Optimizer 선택\n",
        "   - Adam: 대부분의 경우에 좋은 선택\n",
        "   - SGD: 더 세밀한 제어가 필요할 때\n",
        "   - RMSprop: RNN에 효과적\n",
        "\n",
        "2. Loss Function 선택\n",
        "   - Binary Crossentropy: 이진 분류\n",
        "   - Categorical Crossentropy: 다중 분류\n",
        "   - Mean Squared Error: 회귀 문제\n",
        "\n",
        "3. Metrics 선택\n",
        "   - Accuracy: 분류 문제\n",
        "   - Mean Absolute Error: 회귀 문제\n",
        "\n",
        "4. 학습률(Learning Rate) 설정\n",
        "   ```python\n",
        "   from tensorflow.keras.optimizers import Adam\n",
        "   optimizer = Adam(learning_rate=0.001)\n",
        "   model.compile(optimizer=optimizer, ...)\n",
        "   ```\n",
        "\n",
        "5. 사용자 정의 손실 함수나 메트릭 사용 (필요시)\n",
        "\n",
        "### 추가 팁:\n",
        "- `model.summary()`를 사용하여 모델 구조 확인\n",
        "- 복잡한 모델의 경우 시각화 도구 사용 (예: TensorBoard)\n",
        "- 실험을 통해 최적의 하이퍼파라미터 찾기"
      ],
      "metadata": {
        "id": "Ok1rbd3onbz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 모델 레이어 파라미터 가이드"
      ],
      "metadata": {
        "id": "jDVXLDZDnQVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "model = Sequential([\n",
        "    Input(shape=(100,)),\n",
        "    Embedding(100, 32),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "```\n",
        "\n",
        "## 1. Input Layer\n",
        "```python\n",
        "Input(shape=(100,))\n",
        "```\n",
        "- `shape=(100,)`: 각 입력 시퀀스의 길이가 100임을 의미합니다.\n",
        "- 이는 패딩된 시퀀스의 최대 길이와 일치해야 합니다.\n",
        "\n",
        "## 2. Embedding Layer\n",
        "```python\n",
        "Embedding(100, 32)\n",
        "```\n",
        "- 첫 번째 인자 `100`: 어휘 크기(vocabulary size)를 나타냅니다. 이는 데이터셋의 고유한 단어(또는 토큰) 수보다 크거나 같아야 합니다.\n",
        "- 두 번째 인자 `32`: 임베딩 벡터의 차원을 나타냅니다. 이는 조정 가능한 하이퍼파라미터입니다.\n",
        "\n",
        "## 3. LSTM Layers\n",
        "```python\n",
        "LSTM(64, return_sequences=True)\n",
        "LSTM(32)\n",
        "```\n",
        "- `64`와 `32`: LSTM 유닛(셀)의 수를 나타냅니다. 이는 조정 가능한 하이퍼파라미터입니다.\n",
        "- `return_sequences=True`: 첫 번째 LSTM 레이어에서 모든 시간 단계의 출력을 반환합니다. 이는 두 번째 LSTM 레이어로 시퀀스를 전달하기 위해 필요합니다.\n",
        "- 두 번째 LSTM에는 `return_sequences=True`가 없으므로 마지막 시간 단계의 출력만 반환합니다.\n",
        "\n",
        "## 4. Dropout Layers\n",
        "```python\n",
        "Dropout(0.2)\n",
        "```\n",
        "- `0.2`: 20%의 뉴런을 랜덤하게 비활성화합니다. 이 비율은 조정 가능한 하이퍼파라미터입니다.\n",
        "\n",
        "## 5. Dense Layers\n",
        "```python\n",
        "Dense(16, activation='relu')\n",
        "Dense(1, activation='sigmoid')\n",
        "```\n",
        "- `16`: 첫 번째 Dense 레이어의 유닛 수입니다. 이는 조정 가능한 하이퍼파라미터입니다.\n",
        "- `1`: 출력 레이어의 유닛 수입니다. 이진 분류 문제이므로 1개의 유닛을 사용합니다.\n",
        "- `activation='relu'`: ReLU 활성화 함수를 사용합니다.\n",
        "- `activation='sigmoid'`: 이진 분류를 위한 시그모이드 활성화 함수를 사용합니다.\n",
        "\n",
        "## 주의사항:\n",
        "1. Embedding 레이어의 첫 번째 인자(어휘 크기)는 데이터셋의 고유 단어 수보다 크거나 같아야 합니다.\n",
        "2. Input 레이어의 `shape`는 실제 데이터의 shape와 일치해야 합니다.\n",
        "3. LSTM과 Dense 레이어의 유닛 수는 문제의 복잡성과 데이터셋의 크기에 따라 조정할 수 있습니다.\n",
        "4. Dropout 비율은 과적합 정도에 따라 조정할 수 있습니다."
      ],
      "metadata": {
        "id": "0kq1ePtrnW2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SimpleRNN 가이드 및 사용 예시"
      ],
      "metadata": {
        "id": "fi1PimO8rrJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SimpleRNN (Simple Recurrent Neural Network)은 기본적인 형태의 순환 신경망입니다.\n",
        "\n",
        "## 특징\n",
        "- 시퀀스 데이터 처리에 적합\n",
        "- 이전 시점의 정보를 현재 시점으로 전달\n",
        "- 장기 의존성 문제로 인해 긴 시퀀스에서는 성능이 떨어질 수 있음\n",
        "\n",
        "## 주요 용도\n",
        "SimpleRNN은 주로 텍스트나 시계열 데이터 처리에 더 유리합니다. 그 이유는 다음과 같습니다:\n",
        "\n",
        "1. 순차적 정보 처리: 텍스트나 시계열 데이터는 본질적으로 순차적이며, SimpleRNN은 이러한 순차적 정보를 처리하는 데 적합합니다.\n",
        "2. 시간적 의존성: SimpleRNN은 이전 시점의 정보를 다음 시점으로 전달할 수 있어, 텍스트의 문맥이나 시계열 데이터의 시간적 패턴을 잡아낼 수 있습니다.\n",
        "\n",
        "하지만 이미지 처리에도 사용될 수 있습니다:\n",
        "\n",
        "1. 이미지를 1D 시퀀스로 변환: 2D 이미지를 1D 시퀀스로 변환하여 처리할 수 있습니다.\n",
        "2. 특정 이미지 처리 작업: 예를 들어, 이미지 캡션 생성과 같은 작업에서 CNN과 결합하여 사용될 수 있습니다.\n",
        "\n",
        "## 사용 예시\n",
        "\n",
        "### 1. 텍스트 처리 (감성 분석)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "vocab_size = 10000  # 어휘 크기\n",
        "max_length = 100    # 시퀀스 최대 길이\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 32, input_length=max_length),\n",
        "    SimpleRNN(64, return_sequences=True),\n",
        "    SimpleRNN(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "### 2. 시계열 데이터 처리 (주식 가격 예측)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    SimpleRNN(50, activation='relu', input_shape=(None, 1), return_sequences=True),\n",
        "    SimpleRNN(50, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "```\n",
        "\n",
        "### 3. 이미지 처리 (MNIST 손글씨 분류)\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Reshape\n",
        "\n",
        "# MNIST 이미지 크기: 28x28\n",
        "model = Sequential([\n",
        "    Reshape((28, 28), input_shape=(784,)),  # 1D 입력을 2D로 변환\n",
        "    SimpleRNN(128, activation='relu', input_shape=(28, 28)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "이 예시에서는 MNIST 이미지를 28개의 28차원 벡터 시퀀스로 취급합니다.\n",
        "\n",
        "## 주의사항\n",
        "- SimpleRNN은 장기 의존성 문제로 인해 긴 시퀀스에서는 성능이 떨어질 수 있습니다. 이런 경우 LSTM이나 GRU를 고려해볼 수 있습니다.\n",
        "- 이미지 처리에 SimpleRNN을 사용할 때는 일반적으로 CNN보다 성능이 떨어질 수 있습니다. 복잡한 이미지 처리 작업에는 CNN이나 더 발전된 아키텍처를 사용하는 것이 좋습니다."
      ],
      "metadata": {
        "id": "6OCXi3qrrpBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 처리를 위한 딥러닝 모델 가이드"
      ],
      "metadata": {
        "id": "ONxi5a2GrFH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. GRU (Gated Recurrent Unit)\n",
        "GRU는 LSTM의 간소화된 버전으로, 비슷한 성능을 보이면서도 계산 효율성이 더 높습니다.\n",
        "\n",
        "장점:\n",
        "- LSTM보다 간단한 구조로 학습 속도가 빠름\n",
        "- 적은 파라미터로 LSTM과 유사한 성능\n",
        "\n",
        "사용 예:\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 32, input_length=max_length),\n",
        "    GRU(64, return_sequences=True),\n",
        "    GRU(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "```\n",
        "\n",
        "## 2. 1D CNN (1-Dimensional Convolutional Neural Network)\n",
        "1D CNN은 텍스트의 지역적 패턴을 잡아내는 데 효과적이며, 병렬 처리가 가능해 학습 속도가 빠릅니다.\n",
        "\n",
        "장점:\n",
        "- 빠른 학습 속도\n",
        "- 지역적 특징 추출에 효과적\n",
        "\n",
        "사용 예:\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 32, input_length=max_length),\n",
        "    Conv1D(128, 5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "```\n",
        "\n",
        "## 3. Transformer\n",
        "Transformer는 주목(Attention) 메커니즘을 기반으로 하며, 긴 시퀀스 처리에 효과적입니다.\n",
        "\n",
        "장점:\n",
        "- 병렬 처리로 인한 빠른 학습\n",
        "- 장거리 의존성 포착에 탁월\n",
        "\n",
        "사용 예:\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Embedding, MultiHeadAttention, LayerNormalization, Dense, Dropout, GlobalAveragePooling1D\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "    \n",
        "    x = Dense(ff_dim, activation=\"relu\")(res)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = Dense(inputs.shape[-1])(x)\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    \n",
        "    return x + res\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(max_length,)),\n",
        "    Embedding(vocab_size, 32),\n",
        "    transformer_encoder(head_size=32, num_heads=2, ff_dim=32),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "```\n",
        "\n",
        "## 4. BERT (Bidirectional Encoder Representations from Transformers)\n",
        "BERT는 사전 학습된 Transformer 기반 모델로, 다양한 NLP 태스크에서 최고 수준의 성능을 보입니다.\n",
        "\n",
        "장점:\n",
        "- 강력한 텍스트 이해 능력\n",
        "- 다양한 태스크에 적용 가능 (전이 학습)\n",
        "\n",
        "사용 예:\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling1D\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(max_length,), dtype='int32'),\n",
        "    bert.layers[0],\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 입력 데이터 준비 (토큰화 및 패딩)\n",
        "inputs = tokenizer(\"Your text here\", padding=True, truncation=True, return_tensors=\"tf\")\n",
        "```\n",
        "\n",
        "## 선택 가이드:\n",
        "- 간단한 문제, 빠른 학습이 필요한 경우: GRU 또는 1D CNN\n",
        "- 긴 시퀀스, 복잡한 관계 파악이 필요한 경우: Transformer\n",
        "- 최고의 성능이 필요하고 컴퓨팅 리소스가 충분한 경우: BERT"
      ],
      "metadata": {
        "id": "VYhbhr5orC0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 처리를 위한 딥러닝 모델 가이드\n"
      ],
      "metadata": {
        "id": "NL52TvbnrINI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. CNN (Convolutional Neural Network)\n",
        "CNN은 이미지 처리 태스크에서 가장 기본적이고 널리 사용되는 모델입니다.\n",
        "\n",
        "장점:\n",
        "- 이미지의 지역적 특징을 효과적으로 추출\n",
        "- 파라미터 공유로 인한 효율적인 학습\n",
        "\n",
        "사용 예:\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "```\n",
        "\n",
        "## 2. ResNet (Residual Network)\n",
        "ResNet은 skip connection을 사용하여 매우 깊은 네트워크를 효과적으로 학습할 수 있게 합니다.\n",
        "\n",
        "장점:\n",
        "- 매우 깊은 네트워크 학습 가능\n",
        "- 그래디언트 소실 문제 해결\n",
        "\n",
        "사용 예:\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Input, GlobalAveragePooling2D, Dense\n",
        "\n",
        "def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "    y = Conv2D(filters, kernel_size, padding='same', strides=stride)(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = Conv2D(filters, kernel_size, padding='same')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    \n",
        "    if stride != 1 or x.shape[-1] != filters:\n",
        "        x = Conv2D(filters, 1, strides=stride, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "    \n",
        "    out = Add()([x, y])\n",
        "    out = Activation('relu')(out)\n",
        "    return out\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(224, 224, 3)),\n",
        "    Conv2D(64, 7, strides=2, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(3, strides=2, padding='same'),\n",
        "    residual_block(filters=64),\n",
        "    residual_block(filters=64),\n",
        "    residual_block(filters=128, stride=2),\n",
        "    residual_block(filters=128),\n",
        "    residual_block(filters=256, stride=2),\n",
        "    residual_block(filters=256),\n",
        "    residual_block(filters=512, stride=2),\n",
        "    residual_block(filters=512),\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(1000, activation='softmax')\n",
        "])\n",
        "```\n",
        "\n",
        "## 3. Inception\n",
        "Inception 모델은 다양한 크기의 컨볼루션 필터를 병렬로 사용하여 다양한 스케일의 특징을 추출합니다.\n",
        "\n",
        "장점:\n",
        "- 다양한 스케일의 특징 추출\n",
        "- 효율적인 파라미터 사용\n",
        "\n",
        "사용 예:\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Concatenate, GlobalAveragePooling2D, Dense, Input\n",
        "\n",
        "def inception_module(x, filters):\n",
        "    conv1x1 = Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
        "    \n",
        "    conv3x3 = Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
        "    conv3x3 = Conv2D(filters, (3, 3), padding='same', activation='relu')(conv3x3)\n",
        "    \n",
        "    conv5x5 = Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
        "    conv5x5 = Conv2D(filters, (5, 5), padding='same', activation='relu')(conv5x5)\n",
        "    \n",
        "    pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool = Conv2D(filters, (1, 1), padding='same', activation='relu')(pool)\n",
        "    \n",
        "    output = Concatenate()([conv1x1, conv3x3, conv5x5, pool])\n",
        "    return output\n",
        "\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(inputs)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "x = inception_module(x, 64)\n",
        "x = inception_module(x, 120)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "x = inception_module(x, 240)\n",
        "x = inception_module(x, 360)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation='softmax')(x)\n",
        "\n",
        "model = Sequential([inputs, x])\n",
        "```\n",
        "\n",
        "## 4. U-Net\n",
        "U-Net은 인코더-디코더 구조를 가진 모델로, 이미지 세그멘테이션 태스크에 주로 사용됩니다.\n",
        "\n",
        "장점:\n",
        "- 고해상도 특징 보존\n",
        "- 적은 학습 데이터로도 좋은 성능\n",
        "\n",
        "사용 예:\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Input\n",
        "\n",
        "def conv_block(inputs, filters):\n",
        "    x = Conv2D(filters, 3, activation='relu', padding='same')(inputs)\n",
        "    x = Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, filters):\n",
        "    x = conv_block(inputs, filters)\n",
        "    p = MaxPooling2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, filters):\n",
        "    x = UpSampling2D((2, 2))(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, filters)\n",
        "    return x\n",
        "\n",
        "inputs = Input((256, 256, 3))\n",
        "\n",
        "# Encoder\n",
        "e1, p1 = encoder_block(inputs, 64)\n",
        "e2, p2 = encoder_block(p1, 128)\n",
        "e3, p3 = encoder_block(p2, 256)\n",
        "e4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "# Bridge\n",
        "b = conv_block(p4, 1024)\n",
        "\n",
        "# Decoder\n",
        "d1 = decoder_block(b, e4, 512)\n",
        "d2 = decoder_block(d1, e3, 256)\n",
        "d3 = decoder_block(d2, e2, 128)\n",
        "d4 = decoder_block(d3, e1, 64)\n",
        "\n",
        "outputs = Conv2D(1, 1, activation='sigmoid')(d4)\n",
        "\n",
        "model = Sequential([inputs, outputs])\n",
        "```\n",
        "\n",
        "## 선택 가이드:\n",
        "- 일반적인 이미지 분류 태스크: CNN 또는 ResNet\n",
        "- 복잡한 이미지 분류 태스크, 높은 정확도 필요: Inception 또는 ResNet의 변형(예: ResNeXt, DenseNet)\n",
        "- 이미지 세그멘테이션: U-Net 또는 그 변형(예: DeepLab)\n",
        "- 객체 탐지: YOLO, SSD, 또는 Faster R-CNN 계열의 모델"
      ],
      "metadata": {
        "id": "SQsUxg48reoH"
      }
    }
  ]
}